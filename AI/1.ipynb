{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from skimage import morphology,filters\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model,load_model,Sequential\n",
    "from tensorflow.keras.layers import Input,Conv2D,Dense,MaxPooling2D,Softmax,Activation,BatchNormalization,\\\n",
    "    Flatten,Dropout,DepthwiseConv2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\shujuji\\mnist14\n"
     ]
    }
   ],
   "source": [
    "url = \"https://file.liux.pro/d/public/ai-arithmetic/mnist14.tar.gz\"\n",
    "\n",
    "path_to_zip = tf.keras.utils.get_file(origin=url,\n",
    "                                     cache_dir=\".\",\n",
    "                                     cache_subdir=\"shujuji\",\n",
    "                                     extract=True)\n",
    "\n",
    "shujuji_dir = os.path.join(os.path.dirname(path_to_zip),'mnist14')\n",
    "\n",
    "print(shujuji_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "各种图片数量：\n",
      "类别0:11875张\n",
      "类别1:13533张\n",
      "类别2:11984张\n",
      "类别3:12215张\n",
      "类别4:11622张\n",
      "类别5:10875张\n",
      "类别6:11875张\n",
      "类别7:12496张\n",
      "类别8:11741张\n",
      "类别9:11784张\n",
      "类别10:5059张\n",
      "类别11:6500张\n",
      "类别12:5102张\n",
      "类别13:4234张\n"
     ]
    }
   ],
   "source": [
    "data_folder = shujuji_dir\n",
    "\n",
    "x_data = []\n",
    "y_data = []\n",
    "x_data_original = []\n",
    "\n",
    "def thin(image):\n",
    "    erzhi = image > filters.threshold_otsu(image)\n",
    "    gujia = morphology.skeletonize(erzhi)\n",
    "    thin = (gujia * 255).astype(np.uint8)\n",
    "    return thin\n",
    "\n",
    "for label in range(NUM):\n",
    "    label_folder = os.path.join(data_folder,str(label))\n",
    "    images = []\n",
    "    original_images = []\n",
    "    \n",
    "    for image_name in os.listdir(label_folder):\n",
    "        image_path = os.path.join(label_folder,image_name)\n",
    "\n",
    "        image = Image.open(image_path).convert('L')\n",
    "        image = image.resize((28, 28))\n",
    "\n",
    "        image_array = np.array(image)\n",
    "\n",
    "        original_images.append(image_array)\n",
    "\n",
    "        image_array = thin(image_array)\n",
    "\n",
    "        images.append(image_array)\n",
    "    \n",
    "    x_data.extend(images)\n",
    "    y_data.extend([label] * len(images))\n",
    "    x_data_original.extend(original_images)\n",
    "\n",
    "x_data = np.array(x_data)\n",
    "y_data = np.array(y_data)\n",
    "x_data_original = np.array(x_data_original)\n",
    "\n",
    "x_use = x_data\n",
    "y_use = y_data\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x_use, y_use, test_size=0.2, random_state=42)\n",
    "\n",
    "x_train = x_train.reshape(-1,28,28,1).astype('float32')\n",
    "x_test = x_test.reshape(-1,28,28,1).astype('float32')\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range = 1,\n",
    "    zoom_range = (0.7, 1.0),\n",
    "    height_shift_range = 0.05\n",
    ")\n",
    "\n",
    "datagen.fit(x_train)\n",
    "\n",
    "unique, counts = np.unique(y_use,return_counts=True)\n",
    "print(\"各种图片数量：\")\n",
    "for label,count in zip(unique, counts):\n",
    "    print(f'类别{label}:{count}张')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1) / 255\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1) / 255\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=NUM)\n",
    "y_test = to_categorical(y_test, num_classes=NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 14, 14, 4)         104       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 14, 14, 4)         16        \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " activation (Activation)     (None, 14, 14, 4)         0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 14, 14, 4)         0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 5, 5, 4)           404       \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 5, 5, 4)           16        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 5, 5, 4)           0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 14)                1414      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 14)                0         \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 14)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1954 (7.63 KB)\n",
      "Trainable params: 1938 (7.57 KB)\n",
      "Non-trainable params: 16 (64.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def init_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(4, (5, 5), padding='same', strides=(2, 2), input_shape=(28, 28, 1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Conv2D(4, (5, 5), padding='same', strides=(3, 3)))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Activation('relu')) \n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(NUM))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = init_model()\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=[\"categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "881/881 - 19s - loss: 1.4709 - categorical_accuracy: 0.5288 - val_loss: 0.7186 - val_categorical_accuracy: 0.8320 - 19s/epoch - 21ms/step\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gaoguiquan\\.conda\\envs\\ai8051u\\lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "881/881 - 18s - loss: 0.9604 - categorical_accuracy: 0.6751 - val_loss: 0.4817 - val_categorical_accuracy: 0.8856 - 18s/epoch - 21ms/step\n",
      "Epoch 3/30\n",
      "881/881 - 18s - loss: 0.8759 - categorical_accuracy: 0.6949 - val_loss: 0.3988 - val_categorical_accuracy: 0.9150 - 18s/epoch - 21ms/step\n",
      "Epoch 4/30\n",
      "881/881 - 18s - loss: 0.8372 - categorical_accuracy: 0.7041 - val_loss: 0.3360 - val_categorical_accuracy: 0.9198 - 18s/epoch - 21ms/step\n",
      "Epoch 5/30\n",
      "881/881 - 18s - loss: 0.8178 - categorical_accuracy: 0.7089 - val_loss: 0.3166 - val_categorical_accuracy: 0.9197 - 18s/epoch - 20ms/step\n",
      "Epoch 6/30\n",
      "881/881 - 18s - loss: 0.8014 - categorical_accuracy: 0.7111 - val_loss: 0.2981 - val_categorical_accuracy: 0.9276 - 18s/epoch - 21ms/step\n",
      "Epoch 7/30\n",
      "881/881 - 17s - loss: 0.7853 - categorical_accuracy: 0.7164 - val_loss: 0.2820 - val_categorical_accuracy: 0.9311 - 17s/epoch - 20ms/step\n",
      "Epoch 8/30\n",
      "881/881 - 18s - loss: 0.7852 - categorical_accuracy: 0.7153 - val_loss: 0.2725 - val_categorical_accuracy: 0.9308 - 18s/epoch - 21ms/step\n",
      "Epoch 9/30\n",
      "881/881 - 18s - loss: 0.7736 - categorical_accuracy: 0.7184 - val_loss: 0.2659 - val_categorical_accuracy: 0.9312 - 18s/epoch - 20ms/step\n",
      "Epoch 10/30\n",
      "881/881 - 18s - loss: 0.7689 - categorical_accuracy: 0.7192 - val_loss: 0.2854 - val_categorical_accuracy: 0.9306 - 18s/epoch - 20ms/step\n",
      "Epoch 11/30\n",
      "881/881 - 18s - loss: 0.7639 - categorical_accuracy: 0.7210 - val_loss: 0.2500 - val_categorical_accuracy: 0.9363 - 18s/epoch - 21ms/step\n",
      "Epoch 12/30\n",
      "881/881 - 18s - loss: 0.7607 - categorical_accuracy: 0.7203 - val_loss: 0.2547 - val_categorical_accuracy: 0.9347 - 18s/epoch - 20ms/step\n",
      "Epoch 13/30\n",
      "881/881 - 18s - loss: 0.7569 - categorical_accuracy: 0.7222 - val_loss: 0.2489 - val_categorical_accuracy: 0.9371 - 18s/epoch - 20ms/step\n",
      "Epoch 14/30\n",
      "881/881 - 17s - loss: 0.7555 - categorical_accuracy: 0.7215 - val_loss: 0.2483 - val_categorical_accuracy: 0.9375 - 17s/epoch - 20ms/step\n",
      "Epoch 15/30\n",
      "881/881 - 18s - loss: 0.7590 - categorical_accuracy: 0.7205 - val_loss: 0.2463 - val_categorical_accuracy: 0.9374 - 18s/epoch - 21ms/step\n",
      "Epoch 16/30\n",
      "881/881 - 18s - loss: 0.7535 - categorical_accuracy: 0.7223 - val_loss: 0.2867 - val_categorical_accuracy: 0.9259 - 18s/epoch - 21ms/step\n",
      "Epoch 17/30\n",
      "881/881 - 18s - loss: 0.7556 - categorical_accuracy: 0.7217 - val_loss: 0.2427 - val_categorical_accuracy: 0.9394 - 18s/epoch - 21ms/step\n",
      "Epoch 18/30\n",
      "881/881 - 18s - loss: 0.7506 - categorical_accuracy: 0.7229 - val_loss: 0.2339 - val_categorical_accuracy: 0.9369 - 18s/epoch - 21ms/step\n",
      "Epoch 19/30\n",
      "881/881 - 17s - loss: 0.7519 - categorical_accuracy: 0.7226 - val_loss: 0.2324 - val_categorical_accuracy: 0.9402 - 17s/epoch - 20ms/step\n",
      "Epoch 20/30\n",
      "881/881 - 18s - loss: 0.7513 - categorical_accuracy: 0.7230 - val_loss: 0.2358 - val_categorical_accuracy: 0.9386 - 18s/epoch - 20ms/step\n",
      "Epoch 21/30\n",
      "881/881 - 18s - loss: 0.7471 - categorical_accuracy: 0.7235 - val_loss: 0.2361 - val_categorical_accuracy: 0.9385 - 18s/epoch - 20ms/step\n",
      "Epoch 22/30\n",
      "881/881 - 17s - loss: 0.7472 - categorical_accuracy: 0.7231 - val_loss: 0.2338 - val_categorical_accuracy: 0.9383 - 17s/epoch - 19ms/step\n",
      "Epoch 23/30\n",
      "881/881 - 18s - loss: 0.7501 - categorical_accuracy: 0.7235 - val_loss: 0.2307 - val_categorical_accuracy: 0.9379 - 18s/epoch - 20ms/step\n",
      "Epoch 24/30\n",
      "881/881 - 18s - loss: 0.7500 - categorical_accuracy: 0.7225 - val_loss: 0.2288 - val_categorical_accuracy: 0.9394 - 18s/epoch - 20ms/step\n",
      "Epoch 25/30\n",
      "881/881 - 18s - loss: 0.7480 - categorical_accuracy: 0.7236 - val_loss: 0.2319 - val_categorical_accuracy: 0.9391 - 18s/epoch - 21ms/step\n",
      "Epoch 26/30\n",
      "881/881 - 18s - loss: 0.7490 - categorical_accuracy: 0.7225 - val_loss: 0.2398 - val_categorical_accuracy: 0.9352 - 18s/epoch - 20ms/step\n",
      "Epoch 27/30\n",
      "881/881 - 18s - loss: 0.7471 - categorical_accuracy: 0.7231 - val_loss: 0.2268 - val_categorical_accuracy: 0.9402 - 18s/epoch - 20ms/step\n",
      "Epoch 28/30\n",
      "881/881 - 18s - loss: 0.7473 - categorical_accuracy: 0.7226 - val_loss: 0.2566 - val_categorical_accuracy: 0.9340 - 18s/epoch - 20ms/step\n",
      "Epoch 29/30\n",
      "881/881 - 17s - loss: 0.7424 - categorical_accuracy: 0.7240 - val_loss: 0.2309 - val_categorical_accuracy: 0.9387 - 17s/epoch - 20ms/step\n",
      "Epoch 30/30\n",
      "881/881 - 18s - loss: 0.7422 - categorical_accuracy: 0.7250 - val_loss: 0.2407 - val_categorical_accuracy: 0.9369 - 18s/epoch - 21ms/step\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow(x_train, y_train, batch_size=128)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True, mode='min')\n",
    "\n",
    "history = None\n",
    "\n",
    "if sys.platform.startswith('win'):\n",
    "    history = model.fit(train_generator,\n",
    "                        batch_size=1280,\n",
    "                        epochs=30,\n",
    "                        verbose=2,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        callbacks=[early_stopping, model_checkpoint],\n",
    "                        shuffle=True)\n",
    "else:\n",
    "    history = model.fit(train_generator,\n",
    "                        batch_size=1280,\n",
    "                        epochs=30,\n",
    "                        verbose=2,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        callbacks=[early_stopping, model_checkpoint],\n",
    "                        shuffle=True,\n",
    "                        max_queue_size=100,\n",
    "                        workers = 8,\n",
    "                        use_multiprocessing=True)\n",
    "\n",
    "\n",
    "model.load_weights('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "881/881 [==============================] - 1s 1ms/step - loss: 0.2268 - categorical_accuracy: 0.9402\n",
      "\n",
      "测试集的总体准确率: 0.94\n",
      "881/881 [==============================] - 1s 1ms/step\n",
      "\n",
      "每种类别的错误率:\n",
      "类别 0: 0.03\n",
      "类别 1: 0.02\n",
      "类别 2: 0.07\n",
      "类别 3: 0.10\n",
      "类别 4: 0.08\n",
      "类别 5: 0.09\n",
      "类别 6: 0.04\n",
      "类别 7: 0.07\n",
      "类别 8: 0.09\n",
      "类别 9: 0.06\n",
      "类别 10: 0.09\n",
      "类别 11: 0.00\n",
      "类别 12: 0.05\n",
      "类别 13: 0.03\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f'\\n测试集的总体准确率: {test_acc:.2f}')\n",
    "\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "\n",
    "error_rates = {}\n",
    "for label in range(NUM):\n",
    "    label_indices = np.where(y_test_classes == label)[0]\n",
    "    label_correct = np.sum(y_pred_classes[label_indices] == y_test_classes[label_indices])\n",
    "    label_total = len(label_indices)\n",
    "    label_error_rate = 1 - (label_correct / label_total)\n",
    "    error_rates[label] = label_error_rate\n",
    "\n",
    "print(\"\\n每种类别的错误率:\")\n",
    "for label, error_rate in error_rates.items():\n",
    "    print(f'类别 {label}: {error_rate:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ending\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ending\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'ending'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  Args:\n",
      "    args_0: float32 Tensor, shape=(None, 28, 28, 1)\n",
      "  Returns:\n",
      "    float32 Tensor, shape=(None, 14)\n",
      "Done, quant used time:1.1540379524230957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 20:07:54.220563: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE SSE2 SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:From c:\\Users\\Gaoguiquan\\.conda\\envs\\ai8051u\\lib\\site-packages\\tensorflow\\lite\\python\\convert_saved_model.py:42: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.saved_model.load` instead.\n",
      "2025-03-06 20:07:54.241034: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:382] MLIR V1 optimization pass is not enabled\n",
      "2025-03-06 20:07:54.326794: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2025-03-06 20:07:54.327087: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "WARNING:tensorflow:From c:\\Users\\Gaoguiquan\\.conda\\envs\\ai8051u\\lib\\site-packages\\tensorflow\\lite\\python\\util.py:305: convert_variables_to_constants (from tensorflow.python.framework.convert_to_constants) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n",
      "WARNING:tensorflow:From c:\\Users\\Gaoguiquan\\.conda\\envs\\ai8051u\\lib\\site-packages\\tensorflow\\python\\framework\\convert_to_constants.py:946: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This API was designed for TensorFlow v1. See https://www.tensorflow.org/guide/migrate for instructions on how to migrate your code to TensorFlow v2.\n",
      "2025-03-06 20:07:54.463313: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2025-03-06 20:07:54.463621: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "Use '@tf.function' or '@defun' to decorate the function.\n",
      "2025-03-06 20:07:54.506132: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2025-03-06 20:07:54.506279: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONV_2D\n",
      "{'dilation_h_factor': 1, 'dilation_w_factor': 1, 'fused_activation_function': 1, 'padding': 0, 'stride_h': 2, 'stride_w': 2}\n",
      "    input: serving_default_conv2d_input\n",
      "    output: sequential/activation/Relu;StatefulPartitionedCall_1/StatefulPartitionedCall/sequential/activation/Relu;sequential/batch_normalization/FusedBatchNormV3;StatefulPartitionedCall_1/StatefulPartitionedCall/sequential/batch_normalization/FusedBatchNormV3;conv2d/bias;sequential/conv2d/BiasAdd;StatefulPartitionedCall_1/StatefulPartitionedCall/sequential/conv2d/BiasAdd;sequential/conv2d_1/Conv2D;StatefulPartitionedCall_1/StatefulPartitionedCall/sequential/conv2d_1/Conv2D;sequential/conv2d/Conv2D;StatefulPartitionedCall_1/StatefulPartitionedCall/sequential/conv2d/Conv2D1\n",
      "    filter 7: sequential/conv2d/Conv2D;StatefulPartitionedCall_1/StatefulPartitionedCall/sequential/conv2d/Conv2D \n",
      "    bias 6: sequential/activation/Relu;StatefulPartitionedCall_1/StatefulPartitionedCall/sequential/activation/Relu;sequential/batch_normalization/FusedBatchNormV3;StatefulPartitionedCall_1/StatefulPartitionedCall/sequential/batch_normalization/FusedBatchNormV3;conv2d/bias;sequential/conv2d/BiasAdd;StatefulPartitionedCall_1/StatefulPartitionedCall/sequential/conv2d/BiasAdd;sequential/conv2d_1/Conv2D;StatefulPartitionedCall_1/StatefulPartitionedCall/sequential/conv2d_1/Conv2D;sequential/conv2d/Conv2D;StatefulPartitionedCall_1/StatefulPartitionedCall/sequential/conv2d/Conv2D\n",
      "CONV_2D\n",
      "{'dilation_h_factor': 1, 'dilation_w_factor': 1, 'fused_activation_function': 1, 'padding': 0, 'stride_h': 3, 'stride_w': 3}\n",
      "    input: sequential/activation/Relu;StatefulPartitionedCall_1/StatefulPartitionedCall/sequential/activation/Relu;sequential/batch_normalization/FusedBatchNormV3;StatefulPartitionedCall_1/StatefulPartitionedCall/sequential/batch_normalization/FusedBatchNormV3;conv2d/bias;sequential/conv2d/BiasAdd;StatefulPartitionedCall_1/StatefulPartitionedCall/sequential/conv2d/BiasAdd;sequential/conv2d_1/Conv2D;StatefulPartitionedCall_1/StatefulPartitionedCall/sequential/conv2d_1/Conv2D;sequential/conv2d/Conv2D;StatefulPartitionedCall_1/StatefulPartitionedCall/sequential/conv2d/Conv2D1\n",
      "    output: sequential/activation_1/Relu;StatefulPartitionedCall_1/StatefulPartitionedCall/sequential/activation_1/Relu;sequential/batch_normalization_1/FusedBatchNormV3;StatefulPartitionedCall_1/StatefulPartitionedCall/sequential/batch_normalization_1/FusedBatchNormV3;conv2d_1/bias;sequential/conv2d_1/BiasAdd;StatefulPartitionedCall_1/StatefulPartitionedCall/sequential/conv2d_1/BiasAdd;sequential/conv2d_1/Conv2D;StatefulPartitionedCall_1/StatefulPartitionedCall/sequential/conv2d_1/Conv2D1\n",
      "    filter 5: sequential/conv2d_1/Conv2D;StatefulPartitionedCall_1/StatefulPartitionedCall/sequential/conv2d_1/Conv2D \n",
      "    bias 4: sequential/activation_1/Relu;StatefulPartitionedCall_1/StatefulPartitionedCall/sequential/activation_1/Relu;sequential/batch_normalization_1/FusedBatchNormV3;StatefulPartitionedCall_1/StatefulPartitionedCall/sequential/batch_normalization_1/FusedBatchNormV3;conv2d_1/bias;sequential/conv2d_1/BiasAdd;StatefulPartitionedCall_1/StatefulPartitionedCall/sequential/conv2d_1/BiasAdd;sequential/conv2d_1/Conv2D;StatefulPartitionedCall_1/StatefulPartitionedCall/sequential/conv2d_1/Conv2D\n",
      "RESHAPE\n",
      "None\n",
      "    input: sequential/activation_1/Relu;StatefulPartitionedCall_1/StatefulPartitionedCall/sequential/activation_1/Relu;sequential/batch_normalization_1/FusedBatchNormV3;StatefulPartitionedCall_1/StatefulPartitionedCall/sequential/batch_normalization_1/FusedBatchNormV3;conv2d_1/bias;sequential/conv2d_1/BiasAdd;StatefulPartitionedCall_1/StatefulPartitionedCall/sequential/conv2d_1/BiasAdd;sequential/conv2d_1/Conv2D;StatefulPartitionedCall_1/StatefulPartitionedCall/sequential/conv2d_1/Conv2D1\n",
      "    output: sequential/flatten/Reshape;StatefulPartitionedCall_1/StatefulPartitionedCall/sequential/flatten/Reshape\n",
      "    reshape no param\n",
      "FULLY_CONNECTED\n",
      "{'asymmetric_quantize_inputs': False, 'fused_activation_function': 0, 'keep_num_dims': False, 'weights_format': 0}\n",
      "    input: sequential/flatten/Reshape;StatefulPartitionedCall_1/StatefulPartitionedCall/sequential/flatten/Reshape\n",
      "    output: sequential/dense/MatMul;StatefulPartitionedCall_1/StatefulPartitionedCall/sequential/dense/MatMul;sequential/dense/BiasAdd;StatefulPartitionedCall_1/StatefulPartitionedCall/sequential/dense/BiasAdd\n",
      "    weight: sequential/dense/MatMul;StatefulPartitionedCall_1/StatefulPartitionedCall/sequential/dense/MatMul\n",
      "    bias: dense/bias\n",
      "SOFTMAX\n",
      "{'beta': 1.0}\n",
      "OUTPUT!\n",
      "    input: sequential/dense/MatMul;StatefulPartitionedCall_1/StatefulPartitionedCall/sequential/dense/MatMul;sequential/dense/BiasAdd;StatefulPartitionedCall_1/StatefulPartitionedCall/sequential/dense/BiasAdd\n",
      "    output: StatefulPartitionedCall_1\n",
      "    softmax no param\n",
      "ping-pong buf 1568 Byte, ADD-buf 0 Byte; Total 1568 Byte\n",
      "================ pack model head ================\n",
      "mdl_type   =0\n",
      "out_deq    =1\n",
      "input_cnt  =1\n",
      "output_cnt =1\n",
      "layer_cnt  =5\n",
      "buf_size   =1568, keep_size=0, Total=1568\n",
      "sub_size   =0\n",
      "in_dims    = [3, 28, 28, 1]\n",
      "out_dims   = [1, 1, 1, 14]\n",
      "================   pack layers   ================\n",
      "CONV_2D    \n",
      "    [3, 28, 28, 1] [3, 14, 14, 4]\n",
      "    in_oft:0, size:784;  out_oft:784, size:784\n",
      "    padding same(T,B,L,R): 1,2,1,2\n",
      "    layer_size=216\n",
      "CONV_2D    \n",
      "    [3, 14, 14, 4] [3, 5, 5, 4]\n",
      "    in_oft:784, size:784;  out_oft:0, size:104\n",
      "    padding same(T,B,L,R): 1,2,1,2\n",
      "    layer_size=512\n",
      "RESHAPE    \n",
      "    [3, 5, 5, 4] [1, 1, 1, 100]\n",
      "    in_oft:0, size:104;  out_oft:0, size:104\n",
      "    layer_size=48\n",
      "FULLY_CONNECTED    \n",
      "    [1, 1, 1, 100] [1, 1, 1, 14]\n",
      "    in_oft:0, size:104;  out_oft:1552, size:16\n",
      "    layer_size=1576\n",
      "SOFTMAX    \n",
      "    [1, 1, 1, 14] [1, 1, 1, 14]\n",
      "    OUTPUT!\n",
      "    in_oft:1552, size:16;  out_oft:0, size:72\n",
      "    layer_size=48\n",
      "================    pack done!   ================\n",
      "    model  size 2.4KB (2464 B) FLASH\n",
      "    buffer size 1.5KB (1568 B) RAM\n",
      "    single layer mode subbuff size 1.6KB (64+1576=1640 B) RAM\n",
      "Saved to ending.tmdl, ending.h\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "model.export(\"ending\")\n",
    "\n",
    "!python tools/h5_to_tflite.py ending ending.tflite 1 shujuji/mnist14  0to1\n",
    "!python tools/tflite2tmdl.py ending.tflite ending.tmdl int8 1 28,28,1 {NUM} 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
